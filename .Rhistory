cufu_textcoord <- function(A_ca, B_ca){
text_coord_A <- row_pcoord(A_ca)                # coordinates of texts
text_coord_B <- row_pcoord(B_ca)
A_texts_df <- tibble(
text = A_short_fnames,
sub_corp = 'First Decade',
x = text_coord_A[, 1],
y = text_coord_A[, 2])
B_texts_df <- tibble(
text = B_short_fnames,
sub_corp = 'Second Decade',
x = text_coord_B[, 1],
y = text_coord_B[, 2])
texts_df <- rbind(A_texts_df, B_texts_df)
return(texts_df)
}
cufu_wordcoord <- function(A_ca, B_ca, d_A, d_B){
A_word_coord <- col_pcoord(A_ca)                # coordinates of function words
B_word_coord <- col_pcoord(B_ca)
A_words_df <- tibble(
word = colnames(d_A),
x = A_word_coord[, 1],
y = A_word_coord[, 2])
B_words_df <- tibble(
word = colnames(d_B),
x = B_word_coord[, 1],
y = B_word_coord[, 2])
words_df <- rbind(A_words_df, B_words_df)
return(words_df)
}
cufu_textcoord <- function(A_ca, B_ca){
text_coord_A <- row_pcoord(A_ca)                # coordinates of texts
text_coord_B <- row_pcoord(B_ca)
A_texts_df <- tibble(
text = A_short_fnames,
sub_corp = 'First Decade',
x = text_coord_A[, 1],
y = text_coord_A[, 2])
B_texts_df <- tibble(
text = B_short_fnames,
sub_corp = 'Second Decade',
x = text_coord_B[, 1],
y = text_coord_B[, 2])
texts_df <- rbind(A_texts_df, B_texts_df)
return(texts_df)
}
cufu_textcoord <- function(A_ca, B_ca){
text_coord_A <- row_pcoord(A_ca)                # coordinates of texts
text_coord_B <- row_pcoord(B_ca)
A_texts_df <- tibble(
text = A_short_fnames,
sub_corp = 'First Decade',
x = text_coord_A[, 1],
y = text_coord_A[, 2])
B_texts_df <- tibble(
text = B_short_fnames,
sub_corp = 'Second Decade',
x = text_coord_B[, 1],
y = text_coord_B[, 2])
texts_df <- rbind(A_texts_df, B_texts_df)
return(texts_df)
}
cufu_wordcoord <- function(A_ca, B_ca, d_A, d_B){
A_word_coord <- col_pcoord(A_ca)                # coordinates of function words
B_word_coord <- col_pcoord(B_ca)
A_words_df <- tibble(
word = colnames(d_A),
x = A_word_coord[, 1],
y = A_word_coord[, 2])
B_words_df <- tibble(
word = colnames(d_B),
x = B_word_coord[, 1],
y = B_word_coord[, 2])
words_df <- rbind(A_words_df, B_words_df)
return(words_df)
}
# ---
# we make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_A_ca)
# ---
# we make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_A_ca)
words_df <- cufu_wordcoord(d_A_ca, d_A_ca, d_A, d_B)
words_df <- cufu_wordcoord(d_A_ca, d_A_ca, d_A, d_B)
# ---
# we make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# biplot, color coding sub_corp
ggplot(words_df, aes(x = x, y = y)) +
geom_text(aes(label = word), col = "gray") +
geom_point(data = texts_df, aes(x = x, y = y, col = sub_corp))
# -----------------------------------------------------------------------------
# Second CA: top content words
# -----------------------------------------------------------------------------
# retrieve list of high frequency content words
stop_list <- read_types("stop_list.txt")
# For the First Decade
features <- freqlist(A_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 150) %>%
as_types()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the Second Decade
features <- freqlist(B_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 150) %>%
as_types()
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
# ---
# make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# biplot, color coding sub_corp
ggplot(words_df, aes(x = x, y = y)) +
geom_text(aes(label = word), col = "gray") +
geom_point(data = texts_df, aes(x = x, y = y, col = sub_corp))
# For the First Decade
features <- A_fnames %>%
drop_types(stop_list) %>%
freqlist(ngram_size = 2)  %>%
drop_re("(-|--)") %>%
keep_bool(ranks(.) <= 150) %>%
as_types() %>%
print()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
features <- B_fnames %>%
drop_types(stop_list) %>%
freqlist(ngram_size = 2)  %>%
drop_re("(-|--)") %>%
keep_bool(ranks(.) <= 150) %>%
as_types()
d_B <- cufu_funword(features, B_fnames, B_short_fnames)
# conduct CA
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
print(features)
View(d_A)
# build file by feature frequency matrix
d <- data.frame(row.names = features)
for (i in 1:length(fnames)) {
fname <- fnames[[i]]
short_fname <- short_fnames[[i]]
flist <- freqlist(fname, ngram_size = 2)
flist <- flist[features]
d[[short_fname]] <- flist
}
d <- d %>%
as.matrix() %>%
t() %>%
drop_empty_rc()
# -------------------------------------------------------------------
# CA: function words as features
# -------------------------------------------------------------------
cufu_funword <- function(feature,fnames,short_fnames){
# build a data.frame df with in its row names the features
df <- data.frame(row.names = feature)
for (i in 1:length(fnames)) {
fname <- fnames[[i]]             # identify i-th filename
short_fname <- short_fnames[[i]] # identify i-th short filename
flist <- freqlist(fname)         # build frequency list for file
flist <- flist[feature]         # filter that list to just features
df[[short_fname]] <- flist        # add column to d named after filename
}
df <- df %>%
as.matrix() %>%
t()%>%
drop_empty_rc()
return(df)
}
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the First Decade
A_bi <- A_fnames %>%
drop_types(stop_list) %>%
freqlist(ngram_size = 2)  %>%
drop_re("(-|--)") %>%
keep_bool(ranks(.) <= 150) %>%
as_types()
B_bi <- B_fnames %>%
drop_types(stop_list) %>%
freqlist(ngram_size = 2)  %>%
drop_re("(-|--)") %>%
keep_bool(ranks(.) <= 150) %>%
as_types()
d_A <- cufu_funword(A_bi,A_fnames, A_short_fnames)
A_bi %>% print(n=50)
rm(list = ls())
library(tidyverse)
library(mclm)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
cufu_freqlist <- function(X_fnames, stop_list) {
# build frequency list for target corpus
# [use whitespace as token splitter]
# [drop tokens containing ":", "[", or "]" ]
X_flist <- X_fnames %>%
freqlist(re_token_splitter = r"--[(?xi)  \s+   ]--",
re_drop_token     = r"--[(?xi)  [:\[\]] ]--",
file_encoding     = "UTF-8")
# inspecting the top freq. items (after dropping stop words)
# [resorting to concordances when the need arises]
X_flist <- X_flist %>%
drop_types(stop_list)
# return list
return(X_flist)
}
# -------------------------------------------------------------------
# CA: function words as features
# -------------------------------------------------------------------
cufu_funword <- function(feature,fnames,short_fnames){
# build a data.frame df with in its row names the features
df <- data.frame(row.names = feature)
for (i in 1:length(fnames)) {
fname <- fnames[[i]]             # identify i-th filename
short_fname <- short_fnames[[i]] # identify i-th short filename
flist <- freqlist(fname)         # build frequency list for file
flist <- flist[feature]         # filter that list to just features
df[[short_fname]] <- flist        # add column to d named after filename
}
df <- df %>%
as.matrix() %>%
t()%>%
drop_empty_rc()
return(df)
}
cufu_textcoord <- function(A_ca, B_ca){
text_coord_A <- row_pcoord(A_ca)                # coordinates of texts
text_coord_B <- row_pcoord(B_ca)
A_texts_df <- tibble(
text = A_short_fnames,
sub_corp = 'First Decade',
x = text_coord_A[, 1],
y = text_coord_A[, 2])
B_texts_df <- tibble(
text = B_short_fnames,
sub_corp = 'Second Decade',
x = text_coord_B[, 1],
y = text_coord_B[, 2])
texts_df <- rbind(A_texts_df, B_texts_df)
return(texts_df)
}
cufu_wordcoord <- function(A_ca, B_ca, d_A, d_B){
A_word_coord <- col_pcoord(A_ca)                # coordinates of function words
B_word_coord <- col_pcoord(B_ca)
A_words_df <- tibble(
word = colnames(d_A),
x = A_word_coord[, 1],
y = A_word_coord[, 2])
B_words_df <- tibble(
word = colnames(d_B),
x = B_word_coord[, 1],
y = B_word_coord[, 2])
words_df <- rbind(A_words_df, B_words_df)
return(words_df)
}
# United Nations General Debate from the period 2001-2020
A_fnames <-    get_fnames("Data/2001-2010")
B_fnames <-    get_fnames("Data/2011-2020")
# ------------------------------------------------------------------
# Correspondence analysis
# ------------------------------------------------------------------
# get short names
A_short_fnames <- short_names(A_fnames)
B_short_fnames <- short_names(B_fnames)
features <- read_types("function-words.txt") %>%
as_types() %>%
print()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
# ---
# we perform the correspondence analysis and then we ask for a summary
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
# ---
# make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# biplot, color coding sub_corp
ggplot(words_df, aes(x = x, y = y)) +
geom_text(aes(label = word), col = "gray") +
geom_point(data = texts_df, aes(x = x, y = y, col = sub_corp))+
xlim(-1,1)+ ylim(-1,1)
# -----------------------------------------------------------------------------
# Second CA: top content words
# -----------------------------------------------------------------------------
# retrieve list of high frequency content words
stop_list <- read_types("function-words.txt")
# For the First Decade
features <- freqlist(A_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 100) %>%
as_types()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the Second Decade
features <- freqlist(B_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 100) %>%
as_types()
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
# conduct CA
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
# ---
# make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# biplot, color coding sub_corp
ggplot(words_df, aes(x = x, y = y)) +
geom_text(aes(label = word), col = "gray") +
geom_point(data = texts_df, aes(x = x, y = y, col = sub_corp))+
xlim(-1,1)+ ylim(-1,1)
# For the First Decade
features <- freqlist(A_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 120) %>%
as_types()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the Second Decade
features <- freqlist(B_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 120) %>%
as_types()
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
# conduct CA
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
# ---
# make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# biplot, color coding sub_corp
ggplot(words_df, aes(x = x, y = y)) +
geom_text(aes(label = word), col = "gray") +
geom_point(data = texts_df, aes(x = x, y = y, col = sub_corp))+
xlim(-1,1)+ ylim(-1,1)
# x-axis roughly is the most important First Decade (down) vs. Second Decade
# (up) axis So what are the 10 right-most words/items?
words_df %>%
arrange(desc(y)) %>%
head(10) %>%
print()
# x-axis roughly is the most important First Decade (right) vs. Second Decade
# (left) axis So what are the 10 left-most words/items?
words_df %>%
arrange(y) %>%
head(10) %>%
print()
# For the First Decade
features <- freqlist(A_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 150) %>%
as_types()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the Second Decade
features <- freqlist(B_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 150) %>%
as_types()
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
# conduct CA
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
# ---
# make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# -----------------------------------------------------------------------------
# Second CA: top content words
# -----------------------------------------------------------------------------
# retrieve list of high frequency content words
stop_list <- read_types("function-words.txt")
# For the First Decade
features <- freqlist(A_fnames) %>%
drop_types(stop_list) %>%
#keep_bool(ranks(.) <= 150) %>%
as_types()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the Second Decade
features <- freqlist(B_fnames) %>%
drop_types(stop_list) %>%
#keep_bool(ranks(.) <= 150) %>%
as_types()
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
# For the First Decade
features <- freqlist(A_fnames) %>%
drop_types(stop_list) %>%
#keep_bool(ranks(.) <= 150) %>%
as_types()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the Second Decade
features <- freqlist(B_fnames) %>%
drop_types(stop_list) %>%
#keep_bool(ranks(.) <= 150) %>%
as_types()
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
# conduct CA
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
# ---
# make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# biplot, color coding sub_corp
ggplot(words_df, aes(x = x, y = y)) +
geom_text(aes(label = word), col = "gray") +
geom_point(data = texts_df, aes(x = x, y = y, col = sub_corp))
# For the First Decade
features <- freqlist(A_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 1000) %>%
as_types()
d_A <- cufu_funword(features,A_fnames, A_short_fnames)
# For the Second Decade
features <- freqlist(B_fnames) %>%
drop_types(stop_list) %>%
keep_bool(ranks(.) <= 1000) %>%
as_types()
d_B <- cufu_funword(features,B_fnames, B_short_fnames)
# conduct CA
d_A_ca <- ca(d_A)
d_B_ca <- ca(d_B)
# ---
# make preparations for a biplot
#
texts_df <- cufu_textcoord(d_A_ca, d_B_ca)
words_df <- cufu_wordcoord(d_A_ca, d_B_ca, d_A, d_B)
# biplot, color coding sub_corp
ggplot(words_df, aes(x = x, y = y)) +
geom_text(aes(label = word), col = "gray") +
geom_point(data = texts_df, aes(x = x, y = y, col = sub_corp))
# x-axis roughly is the most important First Decade (down) vs. Second Decade
# (up) axis So what are the 10 right-most words/items?
words_df %>%
arrange(desc(y)) %>%
head(10) %>%
print()
# x-axis roughly is the most important First Decade (right) vs. Second Decade
# (left) axis So what are the 10 left-most words/items?
words_df %>%
arrange(y) %>%
head(10) %>%
print()
# x-axis roughly is the most important First Decade (right) vs. Second Decade
# (left) axis So what are the 10 left-most words/items?
words_df %>%
arrange(y) %>%
head(10) %>%
print()
# x-axis roughly is the most important First Decade (down) vs. Second Decade
# (up+right) axis So what are the 10 right-most words/items?
words_df %>%
arrange(desc(y)) %>%
head(10) %>%
print()
words_df %>%
arrange(desc(x)) %>%
head(10) %>%
print()
A_fnames %>%
conc(r"--[(?xi) \b Georgia \b ]--") %>%
print(n = 10)
A_fnames %>%
conc(r"--[(?xi) \b pacific \b ]--") %>%
print(n = 10)
A_fnames %>%
conc(r"--[(?xi) \b ocean \b ]--") %>%
print(n = 10)
B_fnames %>%
conc(r"--[(?xi) \b Azerbaijan \b ]--") %>%
print(n = 10)
# -----------------------------------------------------------
# Finding keyswords in Two decades United Nations General Debate
#      Christine Zhao  r0817014
# -----------------------------------------------------------
install.packages('devtools')
install.packages("D:/BE/Uni/3rd Semester/Methods of Corpus Linguistics/Final/Final Report/cufu.zip", repos = NULL, type = "win.binary")
detach("package:base", unload = TRUE)
library(base)
library(cufu) # self-custumized function to simplify the code
install.packages("D:/BE/Uni/3rd Semester/Methods of Corpus Linguistics/Final/Final Report/cufu.zip", repos = NULL, type = "win.binary")
library(cufu) # self-custumized function to simplify the code
install.packages("D:/BE/Uni/3rd Semester/Methods of Corpus Linguistics/Final/Final Report/cufu.zip", repos = NULL, type = "win.binary")
# -----------------------------------------------------------
# Setting Enviroment
# -----------------------------------------------------------
# install packages if needed
#install.packages('tidyverse')
#install.packages('mclm')
install.packages('cufu')
rm(list = ls())
library(devtools)
devtools::install_github("Christine-Z/cufu")
library(cufu) # self-custumized function to simplify the code
library(tidyverse)
library(mclm)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
# United Nations General Debate from the period 2001-2020
A_fnames <-    get_fnames("Data/2001-2010")
B_fnames <-    get_fnames("Data/2011-2020")
# reading the stop list
stop_list <- read_types("stop_list.txt")
A_flist <- cufu_freqlist(A_fnames,stop_list)%>% print()
